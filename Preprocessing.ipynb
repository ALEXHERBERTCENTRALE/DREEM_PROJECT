{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Minimal frequency with limited amplitude\n",
    "\n",
    "Here we focus on the minimum frequency that ensure the amplitude to be lower than a given limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Frequency with limited amplitude in a Fast Fourier Transform sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequencyWithLimitedAmplitude(fft, amplitude_limit):\n",
    "    for i in range(len(fft)-1,-1,-1):\n",
    "        if fft[i] > amplitude_limit:\n",
    "            return i+1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. General preprocessing method applied to Fast Fourier Transform dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessingFrequencyWithLimitedAmplitude(amplitude_limit):\n",
    "    X_train_fft = h5py.File('X_train_fft.h5','r').copy()\n",
    "    X_test_fft = h5py.File('X_test_fft.h5','r').copy()\n",
    "    keys = list(X_train_fft.keys())\n",
    "    \n",
    "    train_dataset_size = len(X_train_fft[keys.first()])\n",
    "    test_dataset_size = len(X_test_fft[keys.first()])\n",
    "    \n",
    "    X_train_preprocessed = np.zeros((train_dataset_size,len(keys)))\n",
    "    X_test_preprocessed = np.zeros((test_dataset_size,len(keys)))\n",
    "    \n",
    "    for feature_id in range(len(keys)):\n",
    "        feature = keys[feature_id]\n",
    "        train_data = X_train_fft[feature]\n",
    "        for element_id in range(len(train_data)):\n",
    "            element = train_data[element_id]\n",
    "            \n",
    "            # normalization\n",
    "            maxim = max(element)\n",
    "            element = [a/maxim for a in element]\n",
    "            \n",
    "            # preprocessing\n",
    "            X_train_preprocessed[element, feature] = frequencyWithLimitedAmplitude(element, amplitude_limit)\n",
    "            \n",
    "        test_data = X_test_fft[feature]\n",
    "        for element_id in range(len(test_data)):\n",
    "            element = test_data[element_id]\n",
    "            \n",
    "            # normalization\n",
    "            maxim = max(element)\n",
    "            element = [a/maxim for a in element]\n",
    "            \n",
    "            # preprocessing\n",
    "            X_test_preprocessed[element_id, feature_id] = frequencyWithLimitedAmplitude(element, amplitude_limit)   \n",
    "            \n",
    "    return X_train_preprocessed, X_test_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "%pylab inline\n",
    "\n",
    "test = [math.exp(-0.1*x)+(x/8)%0.2 for x in range(100)]\n",
    "plt.plot(range(100),test)\n",
    "plt.plot(range(100),[0.4 for i in range(100)])\n",
    "frequencyWithLimitedAmplitude(test,0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Build and save preprocessed design matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed, X_test_preprocessed = preprocessingFrequencyWithLimitedAmplitude(0.5)\n",
    "\n",
    "np.savetxt('X_train_preprocessed_frequencyWithLimitedAmplitude.txt',X_train_preprocessed, delimiter=',',fmt=\"%s\")\n",
    "np.savetxt('X_test_preprocessed_frequencyWithLimitedAmplitude.txt',X_test_preprocessed, delimiter=',',fmt=\"%s\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Number of pikes\n",
    "Here we count the number of pikes observed in the FFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Calculate the mean amplitude in a frequency interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanOfInterval(fft, freqMin, freqMax):\n",
    "    return mean(fft[freqMin:freqMax])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Build intervals according to a defined width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildIntervals(list_length, interval_width):\n",
    "    return list([i, i+interval_width] for i in range(0,list_length,interval_width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Number of pikes in a Fast Fourier Transform sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pikes(fft, interval_width, amplitude_limit):\n",
    "    intervals = buildIntervals(len(fft), interval_width)\n",
    "    pikes = 0\n",
    "    isIntervalInAPike = [False]\n",
    "    for minim, maxim in intervals:\n",
    "        mean_value = meanOfInterval(fft, minim, maxim)\n",
    "        if mean_value > amplitude_limit:\n",
    "            isIntervalInAPike.append(True)\n",
    "        else:\n",
    "            isIntervalInAPike.append(False)\n",
    "        if not(isIntervalInAPike[-2]) and isIntervalInAPike[-1]:\n",
    "            pikes+=1\n",
    "    print(isIntervalInAPike)\n",
    "    return pikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. General preprocessing method applied to Fast Fourier Transform dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessingPikes(amplitude_limit, interval_width):\n",
    "    X_train_fft = h5py.File('X_train_fft.h5','r').copy()\n",
    "    X_test_fft = h5py.File('X_test_fft.h5','r').copy()\n",
    "    keys = list(X_train_fft.keys())\n",
    "    \n",
    "    train_dataset_size = len(X_train_fft[keys.first()])\n",
    "    test_dataset_size = len(X_test_fft[keys.first()])\n",
    "    \n",
    "    X_train_preprocessed = np.zeros((train_dataset_size,len(keys)))\n",
    "    X_test_preprocessed = np.zeros((test_dataset_size,len(keys)))\n",
    "    \n",
    "    for feature_id in range(len(keys)):\n",
    "        feature = keys[feature_id]\n",
    "        train_data = X_train_fft[feature]\n",
    "        for element_id in range(len(train_data)):\n",
    "            element = train_data[element_id]\n",
    "            \n",
    "            # normalization\n",
    "            maxim = max(element)\n",
    "            element = [a/maxim for a in element]\n",
    "            \n",
    "            # preprocessing\n",
    "            X_train_preprocessed[element_id, feature_id] = pikes(element, interval_width, amplitude_limit)\n",
    "            \n",
    "        test_data = X_test_fft[feature]\n",
    "        for element_id in range(len(test_data)):\n",
    "            element = test_data[element_id]\n",
    "            \n",
    "             # normalization\n",
    "            maxim = max(element)\n",
    "            element = [a/maxim for a in element]\n",
    "            \n",
    "            # preprocessing\n",
    "            X_test_preprocessed[element_id, feature_id] = pikes(element, interval_width, amplitude_limit)\n",
    "            \n",
    "    return X_train_preprocessed, X_test_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildIntervals(100,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "%pylab inline\n",
    "\n",
    "test = [math.exp(-0.1*x)+(x/8)%0.2 for x in range(100)]\n",
    "plt.plot(range(100),test)\n",
    "plt.plot(range(100),[0.1 for i in range(100)])\n",
    "pikes(test, 3, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Build and save preprocessed design matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed, X_test_preprocessed = preprocessingPikes(0.2, 5)\n",
    "\n",
    "np.savetxt('X_train_preprocessed_pikes.txt',X_train_preprocessed, delimiter=',',fmt=\"%s\")\n",
    "np.savetxt('X_test_preprocessed_pikes.txt',X_test_preprocessed, delimiter=',',fmt=\"%s\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Maximum of amplitude\n",
    "In this part, we focus on the maximal amplitude of the FFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Preprocessing method applied to Fast Fourier Transform dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessingMaximum():\n",
    "    X_train_fft = h5py.File('X_train_fft.h5','r').copy()\n",
    "    X_test_fft = h5py.File('X_test_fft.h5','r').copy()\n",
    "    keys = list(X_train_fft.keys())\n",
    "    \n",
    "    train_dataset_size = len(X_train_fft[keys.first()])\n",
    "    test_dataset_size = len(X_test_fft[keys.first()])\n",
    "    \n",
    "    X_train_preprocessed = np.zeros((train_dataset_size,len(keys)))\n",
    "    X_test_preprocessed = np.zeros((test_dataset_size,len(keys)))\n",
    "\n",
    "    for feature_id in range(len(keys)):\n",
    "        feature = keys[feature_id]\n",
    "        train_data = X_train_fft[feature]\n",
    "        for element_id in range(train_dataset_size):\n",
    "            element = train_data[element_id]\n",
    "            \n",
    "            X_train_preprocessed[element_id,feature_id]=max(element)\n",
    "\n",
    "    for feature_id in range(len(keys)):\n",
    "        feature = keys[feature_id]\n",
    "        test_data = X_test_fft[feature]\n",
    "        for element_id in range(test_dataset_size):\n",
    "            element = test_data[element_id]\n",
    "            \n",
    "            X_test_preprocessed[element_id,feature_id]=max(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Build and save preprocessed design matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed, X_test_preprocessed = preprocessingMaximum()\n",
    "\n",
    "np.savetxt('X_train_preprocessed_amplitude.txt',X_train_preprocessed, delimiter=',',fmt=\"%s\")\n",
    "np.savetxt('X_test_preprocessed_amplitude.txt',X_test_preprocessed, delimiter=',',fmt=\"%s\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
